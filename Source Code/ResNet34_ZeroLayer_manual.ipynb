{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6890ceb",
   "metadata": {},
   "source": [
    "# ResNet-34 Transfer Learning for Plant Classification (Manual Split)\n",
    "Zero Additional Hidden Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "265dd7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from torchvision import models, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.transforms import RandAugment\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75c1e729",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    RandAugment(),  #RandAug\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])  #Imagenet mean & std\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "477c0058",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset: 3120 images, 52 classes.\n",
      "Test dataset: 2080 images, 52 classes.\n"
     ]
    }
   ],
   "source": [
    "train_folder = r\"C:\\Users\\dhani\\Documents\\Tugas Akhir and Stuff\\Dataset Manual\\train\"\n",
    "test_folder = r\"C:\\Users\\dhani\\Documents\\Tugas Akhir and Stuff\\Dataset Manual\\test\"\n",
    "\n",
    "train_dataset = ImageFolder(root=train_folder, transform=train_transform)\n",
    "test_dataset = ImageFolder(root=test_folder, transform=test_transform)\n",
    "\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(f\"Train dataset: {len(train_dataset)} images, {len(train_dataset.classes)} classes.\")\n",
    "print(f\"Test dataset: {len(test_dataset)} images, {len(test_dataset.classes)} classes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0cdc78fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import resnet34, ResNet34_Weights, resnet50, ResNet50_Weights, resnet101,ResNet101_Weights\n",
    "\n",
    "weights34 = ResNet34_Weights.IMAGENET1K_V1\n",
    "weights50 = ResNet50_Weights.IMAGENET1K_V1\n",
    "weights101 = ResNet101_Weights.IMAGENET1K_V1\n",
    "model = resnet34(weights=weights34)\n",
    "\n",
    "#freeze conv\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# fc layer config\n",
    "num_classes = 52\n",
    "# zerolayer\n",
    "model.fc = nn.Linear(model.fc.in_features, num_classes)  \n",
    "\n",
    "# onelayer\n",
    "# model.fc = nn.Sequential(\n",
    "#     nn.Linear(model.fc.in_features, 512),\n",
    "#     nn.ReLU(),\n",
    "#     nn.Linear(512, num_classes)        \n",
    "# )       \n",
    "\n",
    "# twolayer\n",
    "# model.fc = nn.Sequential(\n",
    "#     nn.Linear(model.fc.in_features, 512),\n",
    "#     nn.ReLU(),\n",
    "#     nn.Linear(512, 512),\n",
    "#     nn.ReLU(),\n",
    "#     nn.Linear(512, num_classes)        \n",
    "# )                                                      \n",
    "\n",
    "#parameter set\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = Adam(model.fc.parameters(), lr=0.001)\n",
    "\n",
    "device = torch.device('cuda')\n",
    "model = model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8945b3c9",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 42\u001b[0m\n\u001b[0;32m     39\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     40\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m---> 42\u001b[0m running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     44\u001b[0m _, predicted \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(outputs, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     45\u001b[0m total_train \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "train_accuracies = []\n",
    "val_accuracies = []\n",
    "train_f1_scores = []\n",
    "val_f1_scores = []\n",
    "\n",
    "total_start_time = time.time()\n",
    "\n",
    "num_epochs = 50\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "    all_train_labels = []\n",
    "    all_train_preds = []\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Train loop\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        # Forwardprop\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backprop\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total_train += labels.size(0)\n",
    "        correct_train += (predicted == labels).sum().item()\n",
    "\n",
    "        all_train_labels.extend(labels.cpu().numpy())\n",
    "        all_train_preds.extend(predicted.cpu().numpy())\n",
    "\n",
    "    # Train loss, accuracy, F1 score\n",
    "    train_loss = running_loss / len(train_loader)\n",
    "    train_accuracy = 100 * correct_train / total_train\n",
    "    train_f1 = f1_score(all_train_labels, all_train_preds, average='macro')\n",
    "\n",
    "    train_losses.append(train_loss)\n",
    "    train_accuracies.append(train_accuracy)\n",
    "    train_f1_scores.append(train_f1)\n",
    "\n",
    "    # Validation loop\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct_val = 0\n",
    "    total_val = 0\n",
    "    all_val_labels = []\n",
    "    all_val_preds = []\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total_val += labels.size(0)\n",
    "            correct_val += (predicted == labels).sum().item()\n",
    "\n",
    "            all_val_labels.extend(labels.cpu().numpy())\n",
    "            all_val_preds.extend(predicted.cpu().numpy())\n",
    "\n",
    "    # Val loss, accuracy,  F1 score\n",
    "    val_loss = val_loss / len(test_loader)\n",
    "    val_accuracy = 100 * correct_val / total_val\n",
    "    val_f1 = f1_score(all_val_labels, all_val_preds, average='macro')\n",
    "\n",
    "    val_losses.append(val_loss)\n",
    "    val_accuracies.append(val_accuracy)\n",
    "    val_f1_scores.append(val_f1)\n",
    "\n",
    "    epoch_time = time.time() - start_time\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, \"\n",
    "          f\"Train Accuracy: {train_accuracy:.2f}%, Val Accuracy: {val_accuracy:.2f}%, \"\n",
    "          f\"Train F1: {train_f1:.4f}, Val F1: {val_f1:.4f}, Time: {epoch_time:.2f} seconds\")\n",
    "\n",
    "total_training_time = time.time() - total_start_time\n",
    "print(f\"Total Training Time: {total_training_time:.2f} seconds\")\n",
    "\n",
    "results_df = pd.DataFrame({\n",
    "    'Epoch': range(1, num_epochs + 1),\n",
    "    'Train Loss': train_losses,\n",
    "    'Val Loss': val_losses,\n",
    "    'Train Accuracy': train_accuracies,\n",
    "    'Val Accuracy': val_accuracies,\n",
    "    'Train F1 Score': train_f1_scores,\n",
    "    'Val F1 Score': val_f1_scores\n",
    "})\n",
    "results_df.to_csv('training_results_with_34_0.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d4ded55",
   "metadata": {},
   "outputs": [],
   "source": [
    "#savemodel\n",
    "torch.save(model.state_dict(), \"resnet34_ZeroLayer.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
